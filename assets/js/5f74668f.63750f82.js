"use strict";(self.webpackChunkasgardians=self.webpackChunkasgardians||[]).push([[9297],{3905:function(e,t,n){n.d(t,{Zo:function(){return u},kt:function(){return d}});var a=n(7294);function o(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function r(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?r(Object(n),!0).forEach((function(t){o(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):r(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},r=Object.keys(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}var l=a.createContext({}),c=function(e){var t=a.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},u=function(e){var t=c(e.components);return a.createElement(l.Provider,{value:t},e.children)},p={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},h=a.forwardRef((function(e,t){var n=e.components,o=e.mdxType,r=e.originalType,l=e.parentName,u=s(e,["components","mdxType","originalType","parentName"]),h=c(n),d=o,y=h["".concat(l,".").concat(d)]||h[d]||p[d]||r;return n?a.createElement(y,i(i({ref:t},u),{},{components:n})):a.createElement(y,i({ref:t},u))}));function d(e,t){var n=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var r=n.length,i=new Array(r);i[0]=h;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s.mdxType="string"==typeof e?e:o,i[1]=s;for(var c=2;c<r;c++)i[c]=n[c];return a.createElement.apply(null,i)}return a.createElement.apply(null,n)}h.displayName="MDXCreateElement"},9277:function(e,t,n){n.r(t),n.d(t,{frontMatter:function(){return s},contentTitle:function(){return l},metadata:function(){return c},toc:function(){return u},default:function(){return h}});var a=n(7462),o=n(3366),r=(n(7294),n(3905)),i=["components"],s={},l=void 0,c={unversionedId:"Machine Learning/pypackhelp",id:"Machine Learning/pypackhelp",isDocsHomePage:!1,title:"pypackhelp",description:"6. Python-dateutil",source:"@site/docs/Machine Learning/pypackhelp.md",sourceDirName:"Machine Learning",slug:"/Machine Learning/pypackhelp",permalink:"/AsgardiansCode/docs/Machine Learning/pypackhelp",editUrl:"https://github.com/facebook/docusaurus/edit/main/website/docs/Machine Learning/pypackhelp.md",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Machine Learning vs AI vs Deep Learning vs Neural Networks",permalink:"/AsgardiansCode/docs/Machine Learning/MLvsAI"},next:{title:"Introduction",permalink:"/AsgardiansCode/docs/Machine Learning/Computer Vision/Introduction"}},u=[],p={toc:u};function h(e){var t=e.components,n=(0,o.Z)(e,i);return(0,r.kt)("wrapper",(0,a.Z)({},p,n,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("ol",{start:6},(0,r.kt)("li",{parentName:"ol"},"Python-dateutil")),(0,r.kt)("p",null,"If you ever worked with dates in Python, you know doing it without dateutil is a pain.\nIt can compute given the current date, the next month, or the distance between dates in seconds.\nAnd most importantly, it handles the timezone issues for you, which, if you ever tried doing it without a library,\ncan be a massive pain."),(0,r.kt)("ol",{start:9},(0,r.kt)("li",{parentName:"ol"},"TQDM")),(0,r.kt)("p",null,"It\u2019s this little application called TQDM.\nAll it really does is that it gives you a processing bar that you can throw\naround any for loop, and it will give you a progress bar that tells you how long each\niteration takes on average, and most importantly, how long it will take such that you know exactly for how long you can watch YouTube videos before you have to go back to work. 19,300 stars for my favorite package, which gave me more peace of mind in the last years than any other package."),(0,r.kt)("ol",{start:13},(0,r.kt)("li",{parentName:"ol"},"Statsmodels")),(0,r.kt)("p",null,"Statsmodel, in contrast to the fancy new Machine Learning world, is your door to the classical world of statistics. It contains many helpful statistical evaluations and tests. In contrast, these tend to be a lot more stable and surely something any Data Scientist should use every now and then. 6,600 stars are probably more feedback on the coolness of deep learning vs. classical statistics."),(0,r.kt)("ol",{start:15},(0,r.kt)("li",{parentName:"ol"},"NLTK")),(0,r.kt)("p",null,"Short for the Natural Language Toolkit, this is your best friend when you are trying to make sense of any text. It contains extensive algorithms for various grammatical transformations such as stemming and incredible lists of symbols that you might want to remove before processing text in your models, such as dots and stop words. It will also detect what is most likely a sentence and what is not to correct grammatical errors made by the \u201cwriters\u201d of your dataset. All in all, give it a shot if you are working with text. Again 10,000 stars, which is crazy for a niche package like this one"),(0,r.kt)("ol",{start:16},(0,r.kt)("li",{parentName:"ol"},"Scrapy")),(0,r.kt)("p",null,"If you ever tried doing data science without data, I assume you realized that is rather pointless. Luckily the Internet contains information about almost everything. But sometimes, it\u2019s not stored in a nice CSV-like format, and you first have to go out into the wild and gather it. This is exactly where scrapy can help you by making it easy to crawl websites around the globe using a few lines of code. Next time you have an idea where no one pre-gathered the dataset for you. Be sure to check out this 41,000-star project."),(0,r.kt)("ol",{start:17},(0,r.kt)("li",{parentName:"ol"},"Beautiful Soup")),(0,r.kt)("p",null,"A very similar use case, often these web developers store their data in an inferior data structure called HTML. To make use of that nested craziness, beautiful soup has been created. It helps you extract various aspects of the HTML, such as titles and tags, and lets you iterate them like normal dictionaries. It helped me in several little projects where I was interested in user comments on websites that do not offer an open API."),(0,r.kt)("ol",{start:18},(0,r.kt)("li",{parentName:"ol"},"XGBoost")),(0,r.kt)("p",null,"Once our dataset size crosses a certain terabyte threshold, it can be hard to use the common vanilla implementation of Machine Learning algorithms often offered. XGBoost is there to rescue you from waiting weeks for the computations to end. It is a highly scalable and distributed gradient boosting library that will make sure your calculations run as efficiently as possible. Available in almost all common data science languages and stacks."),(0,r.kt)("ol",{start:19},(0,r.kt)("li",{parentName:"ol"},"PySpark")),(0,r.kt)("p",null,"Data Engineering is part of every Data Science workflow, and if you ever tried to process billions of data points, you know that your conventional for loop will only get you this far. PySpark is the Python implementation of the very popular Apache Spark data processing engine. It is like pandas but built with distributed computing in mind from the very beginning. If you ever get the feeling that you can't process your data fast enough to keep track, this surely is exactly what you need. They also started focusing on massive parallel Machine Learning for your very big data use cases. 30,000 stars on Github make it one of the most popular data processing tools out there."),(0,r.kt)("ol",{start:20},(0,r.kt)("li",{parentName:"ol"},"Urllib3")),(0,r.kt)("p",null,"Urllib3 is a powerful, user-friendly HTTP client for Python. If you are trying to do anything with the Internet in Python, this or something that builds on it is a must. API crawlers and connection to various external data sources included. 2,800 stars on GitHub don\u2019t lie."))}h.isMDXComponent=!0}}]);